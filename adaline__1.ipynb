{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7ZTgfCXLsgS"
      },
      "outputs": [],
      "source": [
        "class CustomAdaline(object):\n",
        "\n",
        "    \n",
        "\n",
        "    def __init__(self, n_iterations=100, random_state=1, learning_rate=0.01):\n",
        "\n",
        "        self.n_iterations = n_iterations\n",
        "\n",
        "        self.random_state = random_state\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "\n",
        "    '''\n",
        "\n",
        "    Batch Gradient Descent \n",
        "\n",
        "    \n",
        "\n",
        "    1. Weights are updated considering all training examples.\n",
        "\n",
        "    2. Learning of weights can continue for multiple iterations\n",
        "\n",
        "    3. Learning rate needs to be defined\n",
        "\n",
        "    '''\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        rgen = np.random.RandomState(self.random_state)\n",
        "\n",
        "        self.coef_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
        "\n",
        "        for _ in range(self.n_iterations):\n",
        "\n",
        "              activation_function_output = self.activation_function(self.net_input(X))\n",
        "\n",
        "              errors = y - activation_function_output\n",
        "\n",
        "              self.coef_[1:] = self.coef_[1:] + self.learning_rate*X.T.dot(errors)\n",
        "\n",
        "              self.coef_[0] = self.coef_[0] + self.learning_rate*errors.sum() \n",
        "\n",
        "    \n",
        "\n",
        "    '''\n",
        "\n",
        "    Net Input is sum of weighted input signals\n",
        "\n",
        "    '''\n",
        "\n",
        "    def net_input(self, X):\n",
        "\n",
        "            weighted_sum = np.dot(X, self.coef_[1:]) + self.coef_[0]\n",
        "\n",
        "            return weighted_sum\n",
        "\n",
        "    \n",
        "\n",
        "    '''\n",
        "\n",
        "    Activation function is fed the net input. As the activation function is\n",
        "\n",
        "    an identity function, the output from activation function is same as the\n",
        "\n",
        "    input to the function.\n",
        "\n",
        "    '''\n",
        "\n",
        "    def activation_function(self, X):\n",
        "\n",
        "            return X\n",
        "\n",
        "    \n",
        "\n",
        "    '''\n",
        "\n",
        "    Prediction is made on the basis of output of activation function\n",
        "\n",
        "    '''\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        return np.where(self.activation_function(self.net_input(X)) >= 0.0, 1, 0) \n",
        "\n",
        "    \n",
        "\n",
        "    '''\n",
        "\n",
        "    Model score is calculated based on comparison of \n",
        "\n",
        "    expected value and predicted value\n",
        "\n",
        "    '''\n",
        "\n",
        "    def score(self, X, y):\n",
        "\n",
        "        misclassified_data_count = 0\n",
        "\n",
        "        for xi, target in zip(X, y):\n",
        "\n",
        "            output = self.predict(xi)\n",
        "\n",
        "            if(target != output):\n",
        "\n",
        "                misclassified_data_count += 1\n",
        "\n",
        "        total_data_count = len(X)\n",
        "\n",
        "        self.score_ = (total_data_count - misclassified_data_count)/total_data_count\n",
        "\n",
        "        return self.score_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from sklearn.datasets import load_breast_cancer\n",
        " from sklearn.model_selection import train_test_split\n",
        " import sklearn\n",
        " import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "bc = sklearn.datasets.load_breast_cancer()\n",
        "\n",
        "X = bc.data\n",
        "\n",
        "y = bc.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "adaline = CustomAdaline(n_iterations = 10)\n",
        "# Fit the model\n",
        "adaline.fit(X_train, y_train)\n",
        "# Score the model\n",
        "adaline.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdCgXghDL1_2",
        "outputId": "ed83c938-fc8c-45da-e718-15625075ff7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6257309941520468"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "\n",
        "#Adaline neural network\n",
        "def Adaline(Input, Target, lr=0.2, stop=0.001):\n",
        "\tweight = np.random.random(Input.shape[1])\n",
        "\tbias = np.random.random(1)\n",
        "\t\n",
        "\tError=[stop +1]\n",
        "\t# check the stop condition for the network\n",
        "\twhile Error[-1] > stop or Error[-1]-Error[-2] > 0.0001:\n",
        "\t\terror = []\n",
        "\t\tfor i in range(Input.shape[0]):\n",
        "\t\t\tY_input = sum(weight*Input[i]) + bias\n",
        "\t\t\t\n",
        "\t\t\t# Update the weight\n",
        "\t\t\tfor j in range(Input.shape[1]):\n",
        "\t\t\t\tweight[j]=weight[j] + lr*(Target[i]-Y_input)*Input[i][j]\n",
        "\n",
        "\t\t\t# Update the bias\n",
        "\t\t\tbias=bias + lr*(Target[i]-Y_input)\n",
        "\t\t\t\n",
        "\t\t\t# Store squared error value\n",
        "\t\t\terror.append((Target[i]-Y_input)**2)\n",
        "\t\t# Store sum of square errors\n",
        "\t\tError.append(sum(error))\n",
        "\t\tprint('Error :',Error[-1])\n",
        "\treturn weight, bias\n",
        "\n",
        "# Input dataset\n",
        "x = np.array([[1.0, 1.0, 1.0],\n",
        "\t\t\t[1.0, -1.0, 1.0],\n",
        "\t\t\t[-1.0, 1.0, 1.0],\n",
        "\t\t\t[-1.0, -1.0, -1.0]])\n",
        "# Target values\n",
        "t = np.array([1, 1, 1, -1])\n",
        "\n",
        "w,b = Adaline(x, t, lr=0.2, stop=0.001)\n",
        "print('weight :',w)\n",
        "print('Bias :',b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPnwffcTNAjX",
        "outputId": "e9a79113-4f82-4ed4-bb57-1b88710f4882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error : [2.53420551]\n",
            "Error : [2.07778022]\n",
            "Error : [1.45493434]\n",
            "Error : [1.0076291]\n",
            "Error : [0.69739564]\n",
            "Error : [0.48266036]\n",
            "Error : [0.33404356]\n",
            "Error : [0.23118759]\n",
            "Error : [0.1600022]\n",
            "Error : [0.11073562]\n",
            "Error : [0.07663881]\n",
            "Error : [0.05304082]\n",
            "Error : [0.03670892]\n",
            "Error : [0.02540581]\n",
            "Error : [0.01758306]\n",
            "Error : [0.01216903]\n",
            "Error : [0.00842204]\n",
            "Error : [0.00582879]\n",
            "Error : [0.00403404]\n",
            "Error : [0.00279191]\n",
            "Error : [0.00193225]\n",
            "Error : [0.00133729]\n",
            "Error : [0.00092552]\n",
            "weight : [0.01053319 0.01053319 0.98709953]\n",
            "Bias : [0.01053319]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict from the evaluated weight and bias of adaline\n",
        "def prediction(X,w,b):\n",
        "\ty=[]\n",
        "\tfor i in range(X.shape[0]):\n",
        "\t\tx = X[i]\n",
        "\t\ty.append(sum(w*x)+b)\n",
        "\treturn y\n",
        "prediction(x,w,b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xac2fbD4OQiF",
        "outputId": "ba13c49a-a08c-48d8-d30b-0e5a052f7396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.01869909]),\n",
              " array([0.99763272]),\n",
              " array([0.99763272]),\n",
              " array([-0.99763272])]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MAdaline neural network\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def activation_fn(z):\n",
        "\tif z>=0:\n",
        "\t\treturn 1\n",
        "\telse:\n",
        "\t\treturn -1\n",
        "\n",
        "def Madaline(Input, Target, lr, epoch):\n",
        "\tweight = np.random.random((Input.shape[1],Input.shape[1]))\n",
        "\tbias = np.random.random(Input.shape[1])\n",
        "\t\n",
        "\tw = np.array([0.5 for i in range(weight.shape[1])])\n",
        "\tb = 0.5\n",
        "\tk = 0\n",
        "\twhile k<epoch:\n",
        "\t\terror = []\n",
        "\t\tz_input = np.zeros(bias.shape[0])\n",
        "\t\tz = np.zeros(bias.shape[0])\n",
        "\t\tfor i in range(Input.shape[0]):\n",
        "\t\t\tfor j in range(Input.shape[1]):\n",
        "\t\t\t\tz_input[j] = sum(weight[j]*Input[i]) + bias[j]\n",
        "\t\t\t\tz[j]= activation_fn(z_input[j])\n",
        "\n",
        "\t\t\ty_input = sum(z*w) +b\n",
        "\n",
        "\t\t\ty = activation_fn(y_input)\n",
        "\t\t\t# Update the weight & bias\n",
        "\t\t\tif y != Target[i]:\n",
        "\t\t\t\tfor j in range(weight.shape[1]):\n",
        "\t\t\t\t\tweight[j]= weight[j] + lr*(Target[i]-z_input[j])*Input[i][j]\n",
        "\t\t\t\t\tbias[j] = bias[j] + lr*(Target[i]-z_input[j])\n",
        "\n",
        "\t\t\t# Store squared error value\n",
        "\t\t\terror.append((Target[i]-z_input)**2)\n",
        "\t\t# compute sum of square error\n",
        "\t\tError = sum(error)\n",
        "\t\tprint(k,'>> Error :',Error)\n",
        "\t\tk+=1\n",
        "\t\t\n",
        "\treturn weight, bias\n",
        "\n",
        "# Input dataset\n",
        "x = np.array([[1.0, 1.0, 1.0], [1.0, -1.0, 1.0],\n",
        "\t\t\t[-1.0, 1.0, 1.0], [-1.0, -1.0, -1.0]])\n",
        "# Target values\n",
        "t = np.array([1, 1, 1, -1])\n",
        "\n",
        "w,b = Madaline(x, t, 0.0001, 3)\n",
        "print('weight :',w)\n",
        "print('Bias :',b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG-HJ9ODOeBT",
        "outputId": "81ddc349-d41e-48c6-8134-f0230c030d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 >> Error : [2.91052223 1.82938857 3.0283603 ]\n",
            "1 >> Error : [2.91052223 1.82938857 3.0283603 ]\n",
            "2 >> Error : [2.91052223 1.82938857 3.0283603 ]\n",
            "weight : [[0.83181627 0.41250243 0.66889478]\n",
            " [0.41602884 0.23980865 0.72418516]\n",
            " [0.31037857 0.99469391 0.58924637]]\n",
            "Bias : [0.60751575 0.73001661 0.48974206]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(X, w,b):\n",
        "\ty =[]\n",
        "\tfor i in range(X.shape[0]):\n",
        "\t\tx = X[i]\n",
        "\t\tz1 = x*w\n",
        "\t\tz_1 =[]\n",
        "\t\tfor j in range(z1.shape[1]):\n",
        "\t\t\tz_1.append(activation_fn(sum(z1[j])+b[j]))\n",
        "\t\ty_in = sum(np.array(z_1)*np.array([0.5 for j in range(w.shape[1])])) + 0.5\n",
        "\t\ty.append(activation_fn(y_in))\n",
        "\treturn y\n",
        "\n",
        "prediction(x, w,b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dufZkvWOQiPO",
        "outputId": "c69a4464-1a0b-4cf1-f5ec-61221659e29a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, -1]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-BjFsSrsQoZk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}